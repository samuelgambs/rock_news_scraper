import os
from src.scrapers.blabbermouth_scraper import BlabbermouthScraper
from src.scrapers.bravewords_scraper import BraveWordsScraper
from src.scrapers.metalinjection_scraper import MetalInjectionScraper
from src.scrapers.loudwire_scraper import LoudwireScraper
from src.scrapers.metaltalk_scraper import MetalTalkScraper
from src.scrapers.metalsucks_scraper import MetalSucksScraper
from src.utils.news_storage import NewsStorage
# from src.utils.extract_named_entities import process_news_entities
from src.utils.translator import translate_news
from src.utils.wordpress_publisher import postar_no_wordpress
from dotenv import load_dotenv

# Carrega as variÃ¡veis do arquivo .env.local
load_dotenv(".env.local")

# Agora vocÃª pode acessar as variÃ¡veis como se estivessem no ambiente do sistema
WORDPRESS_URL = os.getenv("WORDPRESS_URL")
WORDPRESS_USER = os.getenv("WORDPRESS_USER")
WORDPRESS_PASSWORD = os.getenv("WORDPRESS_PASSWORD")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# ğŸ”¥ Defina o limite de notÃ­cias por site
LIMIT_PER_SITE = 1

def main():
    """Fluxo principal do script"""
    
    # ğŸ—‘ï¸ Exclui o arquivo de armazenamento antes de comeÃ§ar
    # if os.path.exists("news_storage.json"):
    #     os.remove("news_storage.json")
    #     print("ğŸ—‘ï¸ Arquivo news_storage.json excluÃ­do antes da execuÃ§Ã£o.")

    # ğŸ“¦ Inicializa o armazenamento
    storage = NewsStorage()
    # translate = Translator()


    # ğŸ“° Lista de scrapers
    scrapers = [
        BlabbermouthScraper(storage),
        BraveWordsScraper(storage),
        MetalInjectionScraper(storage),
        LoudwireScraper(storage),
        MetalTalkScraper(storage),
        MetalSucksScraper(storage),
    ]

#     for scraper in scrapers:
#         print(f"ğŸ” Coletando notÃ­cias de {scraper.__class__.__name__}...")
        
#         news_list = scraper.fetch_articles(limit=LIMIT_PER_SITE)
        
#         for news in news_list:
#             # Traduzir notÃ­cia
#             print(f"ğŸŒ Traduzindo: {news['title']}...")
#             translated_title = translator.translate_text(news["title"])
#             translated_content = translator.translate_text(news["content"])
#             news["translated_title"] = translated_title
#             news["translated_content"] = translated_content
#             storage.add_news(**news)  # Armazena a versÃ£o traduzida imediatamente
            
#             # Publicar no WordPress
#             print(f"ğŸ“ Publicando no WordPress: {translated_title}...")
#             postar_no_wordpress(translated_title, translated_content, news["image_url"], news["entities"])

#     print("âœ… Processo concluÃ­do!")

# if __name__ == "__main__":
#     main()

    # 1ï¸âƒ£ Coletar notÃ­cias
    for scraper in scrapers:
        print(f"ğŸ” Coletando notÃ­cias de {scraper.__class__.__name__}...")
        scraper.fetch_articles(limit=LIMIT_PER_SITE)

    print("âœ… Todas as notÃ­cias foram coletadas com sucesso!")

    # 2ï¸âƒ£ Traduzir antes de processar as entidades
    print("ğŸŒ Traduzindo notÃ­cias para PortuguÃªs...")
    translate_news(storage)

    # 3ï¸âƒ£ Processar entidades no texto traduzido
    # print("ğŸ§  Processando entidades nomeadas nas notÃ­cias traduzidas...")
    # process_news_entities(storage)

    # 4ï¸âƒ£ Publicar no WordPress
    print("ğŸ“ Publicando notÃ­cias no WordPress...")
    postar_no_wordpress(storage)

    print("âœ… Processo finalizado!")
if __name__ == "__main__":
    main()
